ğŸ” Duplicate Question Pair â€“ Quora NLP Project
â€œDo these two questions mean the same thing?â€ ğŸ¤”ğŸ’¬

This project detects whether two given questions are semantically identical, even if they use different words.
Built as a continuation of an NLP course, it leverages feature-rich Machine Learning on the Quora Question Pairs dataset.

ğŸ§  Problem Statement
Quora aims to merge questions with the same intent to improve search and reduce duplicates.

â“ Can we automatically detect when two questions mean the same thing?
âœ… Yesâ€”using advanced feature engineering and ML.

ğŸ“Š Dataset & EDA
Size: ~400,000 question pairs (â‰ˆ63 % non-duplicate, â‰ˆ37 % duplicate).
Repetition: ~111k unique questions appear multiple times, some 100+ times.
Baseline: Bag-of-Words + Random Forest on 30k sample â†’ ~74.5 % accuracy.

ğŸ—ï¸ Feature Engineering
Text Pre-processing
Lowercasing, de-contractions, special-char replacement, punctuation & numeric cleanup.
Basic Features (7)
Char/word counts, common & unique word counts, word-share ratio, etc.
Advanced Features (15)
Token Ratios: common/min & common/max words/tokens/stopwords, first/last word match flags.
Length Metrics: mean/abs diff of token lengths, longest common substring ratio.
Fuzzy Scores: fuzz_ratio, fuzz_partial_ratio, token_sort_ratio, token_set_ratio.
Bag-of-Words
6,000-dimensional BoW vectors for each question.

ğŸ† Feature engineering boosted Random Forest accuracy to ~78 %.

ğŸ¤– Modeling & Results
Model	Accuracy	Key Insight
Random Forest (6022 features)	78 %	Fewer false positives (critical for Quora UX)
XGBoost	78.2 %	Slightly higher accuracy but more false positives
Metric Choice: False positives (merging non-duplicates) hurt more than false negatives, so Random Forest chosen despite marginally lower accuracy.

ğŸš€ Deployment
Framework: Streamlit web app, deployed to Heroku.
Artifacts: Pickled Random Forest model + CountVectorizer.
Pipeline: query_point_creator() handles all preprocessing & feature extraction for new input.

User â¡ï¸ Streamlit UI â¡ï¸ Preprocessing & Feature Pipeline â¡ï¸ Random Forest â¡ï¸ Duplicate? âœ…/âŒ

ğŸ“¦ Project Structure
File / Folder	Description
app.py	Streamlit application entry point
model/	Pickled Random Forest model & CountVectorizer
feature_engineering.py	Functions for basic, advanced & fuzzy features
preprocessing.py	Text cleaning and de-contraction logic
requirements.txt	Python dependencies
notebooks/EDA.ipynb	Exploratory analysis and baseline modeling
query_point_creator.py	Full feature-creation pipeline for new questions


ğŸ› ï¸ Technologies Used
Language: Python
ML / NLP: scikit-learn, XGBoost, fuzzywuzzy, NLTK
Visualization: matplotlib, seaborn, t-SNE
Deployment: Streamlit, Heroku
Data Handling: pandas, NumPy

âš¡ Installation & Setup
git clone https://github.com/yourusername/Duplicate-Question-Pair.git
cd Duplicate-Question-Pair
python -m venv venv
source venv/bin/activate      # Windows: venv\Scripts\activate
pip install -r requirements.txt
streamlit run app.py

Visit http://localhost:8501 to test the app.

ğŸ“ˆ Future Improvements
Scale Training: Train on full dataset using Dask/Vaex or cloud compute.
Richer Embeddings: TF-IDF, Word2Vec, or TF-IDF-weighted Word2Vec (initial tests â‰ˆ80 %).
Deep Learning: LSTMs or Transformer models (e.g., BERT) for semantic similarity.
Hyperparameter Search: Grid/Random search for further gains.
Probability-Based Evaluation: Use predict_proba + log loss for nuanced metrics.

âœ¨ Key Insights
Feature Engineering Drives NLP Success: Simple ratios and fuzzy scores meaningfully outperformed plain BoW.
Preprocessing is Critical: Consistent text cleaning improves downstream features.
Consider Business Costs: Evaluate confusion matrix, not just accuracyâ€”false positives were more costly for Quora.
Iterative Refinement Pays Off: Start simple, add features, tune models incrementally.

ğŸ‘¨â€ğŸ’» Author
Made with ğŸ§‘â€ğŸ’» and â¤ï¸ by Manthan Jadav
LinkedIn
GitHub
ğŸ“§ manthanjadav746@gmail.com

ğŸ“œ License
This project is licensed under the MIT License â€“ feel free to fork, improve, and share!
